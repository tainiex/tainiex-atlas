
name: Build and Deploy to Cloud Run

on:
  push:
    branches:
      - main

env:
  PROJECT_ID: ${{ secrets.GCP_PROJECT_ID }}
  CLOUD_RUN_REGION: us-central1
  CLOUD_RUN_SERVICE_NAME: tainiex-atlas
  REPO_NAME: tainiex-atlas

# Auto-cancel previous deployments when a new one is triggered
concurrency:
  group: deploy-${{ github.ref }}
  cancel-in-progress: true

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      contents: 'read'
      id-token: 'write'
      packages: 'write'

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      # Authentication via Service Account Key JSON
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      # Install via pnpm
      - name: Setup pnpm
        uses: pnpm/action-setup@v4

      # Setup Node.js
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'pnpm'
          registry-url: 'https://npm.pkg.github.com'

      # Install Dependencies and Build
      - name: Install and Build
        run: |
          # Configure npm auth for CI
          echo "//npm.pkg.github.com/:_authToken=${GITHUB_TOKEN}" >> .npmrc
          
          # Install all dependencies
          pnpm install --frozen-lockfile

          # Build Shared Library first (Required for typecheck)
          pnpm --filter @tainiex/shared-atlas run build
          
          # Run Type Check (Catch errors SWC might skip)
          pnpm run typecheck

          # Build the application
          pnpm run build
          
          # Prune to production dependencies for the Docker image
          # pnpm deploy or pruning is different. 
          # For now, let's just use strict production install if needed, or rely on the Dockerfile to do prod install.
          # The Dockerfile I updated does `pnpm install --prod`.
          # So here we just need to build.
          # We can skip pruning here if Dockerfile handles it, BUT the previous flow copied node_modules.
          # Let's align: 
          # 1. Build here.
          # 2. Dockerfile does `pnpm install --prod`. 
          # So we DON'T copy node_modules from here to Docker context effectively if Dockerfile installs it.
          # BUT wait, the previous Dockerfile COPIED node_modules. 
          # To keep it fast, we should probably prune here and copy.
          pnpm prune --prod
        env:
          NODE_AUTH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      # Configure Docker to use gcloud command-line tool as a credential helper
      - name: Configure Docker for GCR
        run: gcloud auth configure-docker

      # Build and Push Container
      - name: Build and Push Container
        id: build-image
        run: |
          # Define image tag for GCR
          IMAGE_TAG=gcr.io/${{ env.PROJECT_ID }}/${{ env.CLOUD_RUN_SERVICE_NAME }}:${{ github.sha }}
          
          docker build -t $IMAGE_TAG .
          docker push $IMAGE_TAG
          
          # Set the image tag as an output for the next step
          echo "image=$IMAGE_TAG" >> $GITHUB_OUTPUT

      # Deploy to Cloud Run
      - name: Deploy to Cloud Run
        run: |
          # Create env.yaml for atomic environment variable replacement
          cat <<EOF > env.yaml
          NODE_ENV: "production"
          LOG_LEVEL: "info"
          API_PREFIX: "api"
          VERTEX_LOCATION: "us-central1"
          VERTEX_MODEL: "gemini-3-pro-preview"
          DB_SSL: "true"
          CORS_ORIGIN: "https://*.tainiex.com"
          VERTEX_PROJECT_ID: "${{ secrets.GCP_PROJECT_ID }}"
          JWT_SECRET: "${{ secrets.JWT_SECRET }}"
          JWT_REFRESH_SECRET: "${{ secrets.JWT_REFRESH_SECRET }}"
          DB_HOST: "${{ secrets.DB_HOST }}"
          DB_PORT: "${{ secrets.DB_PORT }}"
          DB_USERNAME: "${{ secrets.DB_USERNAME }}"
          DB_PASSWORD: "${{ secrets.DB_PASSWORD }}"
          DB_NAME: "${{ secrets.DB_NAME }}"
          GOOGLE_CLIENT_ID: "${{ secrets.GOOGLE_CLIENT_ID }}"
          GOOGLE_CLIENT_SECRET: "${{ secrets.GOOGLE_CLIENT_SECRET }}"
          AZURE_CLIENT_ID: "${{ secrets.AZURE_CLIENT_ID }}"
          COOKIE_DOMAIN: ".tainiex.com"
          GCS_BUCKET_NAME: "tainiex-atlas"
          GCS_SERVICE_ACCOUNT: "${{ secrets.CLOUD_RUN_GCP_SERVICE_ACCOUNT }}"
          EOF

          # Deploy using --env-vars-file which replaces all existing env vars
          gcloud run deploy ${{ env.CLOUD_RUN_SERVICE_NAME }} \
            --region ${{ env.CLOUD_RUN_REGION }} \
            --image ${{ steps.build-image.outputs.image }} \
            --service-account ${{ secrets.CLOUD_RUN_GCP_SERVICE_ACCOUNT }} \
            --env-vars-file env.yaml \
            --timeout=3600 \
            --no-cpu-throttling \
            --session-affinity
